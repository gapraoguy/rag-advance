#!/usr/bin/env python3

import sys
import os
import logging
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent / "src"))

from config.settings import Settings
from application.services.benchmark_service import BenchmarkService
from infrastructure.repositories.json_product_repository import JsonProductRepository
from infrastructure.repositories.chroma_vector_search_repository import ChromaVectorSearchRepository


def setup_logging():
    """ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('benchmark.log')
        ]
    )


def main():
    """ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    try:
        setup_logging()
        logger = logging.getLogger(__name__)
        
        print("="*60)
        print("ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ")
        print("="*60)
        
        settings = Settings.from_env()
        logger.info("Settings loaded successfully")
        
        if not settings.openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        product_repo = JsonProductRepository(settings)
        
        def create_vector_repo(strategy: str, clear_existing: bool = True):
            collection_name = f"{settings.chroma_collection_name}_{strategy}"
            strategy_settings = Settings(
                openai_api_key=settings.openai_api_key,
                llm_model=settings.llm_model,
                embedding_model=settings.embedding_model,
                temperature=settings.temperature,
                chroma_persist_directory=settings.chroma_persist_directory,
                chroma_collection_name=collection_name,
                data_directory=settings.data_directory,
                products_file=settings.products_file,
                faq_file=settings.faq_file,
                support_file=settings.support_file,
                default_search_results=settings.default_search_results,
                chunk_strategy=strategy
            )
            
            if clear_existing:
                vector_repo = ChromaVectorSearchRepository(strategy_settings)
                try:
                    vector_repo.delete_collection()
                    logger.info(f"Cleared existing collection: {collection_name}")
                except:
                    pass
                return ChromaVectorSearchRepository(strategy_settings)
            else:
                return ChromaVectorSearchRepository(strategy_settings)
        
        benchmark_service = BenchmarkService(
            product_repo=product_repo,
            settings=settings,
            vector_repo_factory=create_vector_repo
        )
        
        print("\nğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        print("ä»¥ä¸‹ã®æˆ¦ç•¥ã‚’æ¯”è¼ƒè©•ä¾¡ã—ã¾ã™:")
        print("- UNIFIED: å…¨æƒ…å ±çµ±åˆå‹")
        print("- SECTION: ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²å‹") 
        print("- GRANULAR: ç´°ç²’åº¦åˆ†å‰²å‹")
        print("\nãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­...")
        
        results = benchmark_service.run_full_benchmark(top_k=3)
        
        benchmark_service.print_summary(results)
        
        output_file = benchmark_service.save_benchmark_results(results)
        print(f"\nè©³ç´°çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        
        summary = results.get("summary", {})
        if "performance_overview" in summary:
            unified_f1 = summary["performance_overview"].get("unified", {}).get("f1_score", 0)
            
            best_f1 = 0
            best_strategy = "unified"
            for strategy, metrics in summary["performance_overview"].items():
                if metrics["f1_score"] > best_f1:
                    best_f1 = metrics["f1_score"]
                    best_strategy = strategy
            
            if best_strategy != "unified":
                improvement_pct = ((best_f1 - unified_f1) / unified_f1 * 100) if unified_f1 > 0 else 0
                print(f"\nğŸ‰ Issue #4å®Œäº†æ¡ä»¶é”æˆçŠ¶æ³:")
                print(f"æœ€é«˜æ€§èƒ½: {best_strategy.upper()}æˆ¦ç•¥ (F1: {best_f1:.3f})")
                if improvement_pct >= 10:
                    print(f"âœ… 10%ä»¥ä¸Šã®ç²¾åº¦å‘ä¸Šã‚’é”æˆ! ({improvement_pct:.1f}%å‘ä¸Š)")
                else:
                    print(f"âš ï¸  æ”¹å–„ã¯è¦‹ã‚‰ã‚Œã¾ã™ãŒ10%ã«ã¯å±Šãã¾ã›ã‚“ã§ã—ãŸ ({improvement_pct:.1f}%å‘ä¸Š)")
            else:
                print(f"\nğŸ“Š çµ±åˆå‹æˆ¦ç•¥ãŒæœ€é«˜æ€§èƒ½ã§ã—ãŸ (F1: {best_f1:.3f})")
        
        print("\nâœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
        
    except KeyboardInterrupt:
        print("\nâŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(f"Benchmark failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 